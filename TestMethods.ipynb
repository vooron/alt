{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker start bert-as-service\n",
    "\n",
    "\n",
    "# try with examples encoded into 1 vector\n",
    "# try with cont learning (update indexes)\n",
    "# try with SGDRegressor\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.metrics import f1_score\n",
    "from bert_serving.client import BertClient\n",
    "from timeit import default_timer as timer\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Optional, Dict, List, Tuple, Callable\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "class Command(NamedTuple):\n",
    "    code: str\n",
    "    title: str = None\n",
    "    description: str = None\n",
    "    examples: Optional[List[str]] = None\n",
    "\n",
    "\n",
    "class IndexedCommand(NamedTuple):\n",
    "    command: Command\n",
    "    index: np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Preprocessor:\n",
    "    \n",
    "    def __init__(self, remove_stop_words: bool):\n",
    "        self.remove_stop_words = remove_stop_words\n",
    "    \n",
    "    stop_words = set(STOP_WORDS)\n",
    "    \n",
    "    def preprocess(self, text: str) -> str:\n",
    "        lc_cleared = text.lower()\n",
    "        lc_cleared = re.sub(r\"[0-9.,?/()\\[\\]\\'\\\":#â„–$\\t;<>!+\\-_=%{}><~`|]\", \" \", lc_cleared)\n",
    "        lc_cleared = re.sub(r\"\\s+\", \" \", lc_cleared)\n",
    "        \n",
    "        lc_cleared = lc_cleared.strip()\n",
    "        \n",
    "        if self.remove_stop_words:\n",
    "            return \" \".join(list(filter(lambda x: x not in self.stop_words, lc_cleared.split(\" \"))))\n",
    "        else:\n",
    "            return lc_cleared\n",
    "\n",
    "\n",
    "class Indexer(metaclass=ABCMeta):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_index(self, text: str) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    \n",
    "class Word2VecIndexer(Indexer):\n",
    "    \n",
    "    def __init__(self, mapper):\n",
    "        self.mapper = mapper\n",
    "    \n",
    "    def get_index(self, text: str) -> np.ndarray:\n",
    "        embedding = self.mapper(text)\n",
    "        if embedding.has_vector:\n",
    "            return embedding.vector\n",
    "\n",
    "\n",
    "    \n",
    "class BertIndexer(Indexer):\n",
    "    \n",
    "    def __init__(self, mapper):\n",
    "        self.mapper = mapper\n",
    "    \n",
    "    def get_index(self, text: str) -> np.ndarray:\n",
    "        return self.mapper.encode([text])[0]\n",
    "\n",
    "        \n",
    "\n",
    "class Predictor:\n",
    "\n",
    "    \n",
    "    def rate_commands(self, indexed_commands: List[IndexedCommand], query_index: np.ndarray) -> List[Tuple[str, float]]:\n",
    "        target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n",
    "        \n",
    "        commands, commands_indexes = target_vocab[::, 0], target_vocab[::, 1]\n",
    "        \n",
    "        a = np.array([np.array(x) for x in commands_indexes])\n",
    "        b = query_index\n",
    "\n",
    "        predict = (np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b)) + 1) / 2\n",
    "\n",
    "        return list(sorted(zip(commands, predict), key=lambda x: x[1], reverse=True))\n",
    "        \n",
    "\n",
    "\n",
    "class Resolver:\n",
    "    \n",
    "    def resolve(self, prediction: List[Tuple[str, float]]) -> str:\n",
    "        return prediction[0][0]\n",
    "\n",
    "\n",
    "def title_description_commands_indexer(commands: List[Command], preprocessor: Preprocessor, indexer: Indexer):\n",
    "    indexed_commands = []\n",
    "\n",
    "    for command in commands:\n",
    "        text_to_index = preprocessor.preprocess(command.title + \" \" + command.description)\n",
    "        indexed_commands.append(IndexedCommand(\n",
    "            command=command,\n",
    "            index=indexer.get_index(text_to_index)\n",
    "        ))\n",
    "    return indexed_commands\n",
    "\n",
    "\n",
    "def examples_commands_indexer(commands: List[Command], preprocessor: Preprocessor, indexer: Indexer):\n",
    "    indexed_commands = []\n",
    "\n",
    "    for command in commands:\n",
    "        # for w2v mean of vectors for each sentence is the same that vector for concatenated message (99%)\n",
    "        # for bert (<87%)\n",
    "        examples = preprocessor.preprocess(\" \".join(command.examples))\n",
    "        indexed_commands.append(IndexedCommand(\n",
    "            command=command,\n",
    "            index=indexer.get_index(examples)\n",
    "        ))\n",
    "    return indexed_commands\n",
    "\n",
    "\n",
    "def mean_examples_commands_indexer(commands: List[Command], preprocessor: Preprocessor, indexer: Indexer):\n",
    "    indexed_commands = []\n",
    "\n",
    "    for command in commands:\n",
    "        indexed_commands.append(IndexedCommand(\n",
    "            command=command,\n",
    "            index=reduce(lambda x, acc: x + acc, [indexer.get_index(t) for t in command.examples]) / len(command.examples)\n",
    "        ))\n",
    "    return indexed_commands\n",
    "\n",
    "\n",
    "def bert_pair_sentances_examples_commands_indexer(commands: List[Command], preprocessor: Preprocessor, indexer: Indexer):\n",
    "    indexed_commands = []\n",
    "\n",
    "    for command in commands:\n",
    "        indexed_commands.append(IndexedCommand(\n",
    "            command=command,\n",
    "            index=indexer.get_index(\" ||| \".join(command.examples))\n",
    "        ))\n",
    "    return indexed_commands\n",
    "\n",
    "\n",
    "class IndexUpdater:\n",
    "    coef: float\n",
    "        \n",
    "    def __init__(self, coef: float):\n",
    "        assert 0 <= coef <= 1\n",
    "        self.coef = coef\n",
    "        \n",
    "    def update_index(self, command_index: np.array, query_index: np.array):\n",
    "        return (1 - self.coef) * command_index + self.coef * query_index\n",
    "    \n",
    "\n",
    "class Pipeline:\n",
    "    preprocessor: Preprocessor\n",
    "    indexer: Indexer\n",
    "    predictor: Predictor\n",
    "    resolver: Resolver\n",
    "    indexed_commands: List[IndexedCommand]\n",
    "    index_updater: Optional[IndexUpdater]\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        preprocessor: Preprocessor,\n",
    "        indexer: Indexer,\n",
    "        predictor: Predictor,\n",
    "        resolver: Resolver,\n",
    "        commands: List[Command],\n",
    "        commands_indexer: Callable[[List[Command], Preprocessor, Indexer], List[IndexedCommand]],\n",
    "        index_updater: Optional[IndexUpdater] = None\n",
    "    ):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.indexer = indexer\n",
    "        self.predictor = predictor\n",
    "        self.resolver = resolver\n",
    "        self.index_updater = index_updater\n",
    " \n",
    "        self.indexed_commands = commands_indexer(commands, preprocessor, indexer)\n",
    "    \n",
    "    def train(self, query: str, target: str) -> 'Pipeline':\n",
    "        clean_query = self.preprocessor.preprocess(query)\n",
    "        indexed_query = self.indexer.get_index(clean_query)\n",
    "        rating = self.predictor.rate_commands(self.indexed_commands, indexed_query)\n",
    "        prediction = self.resolver.resolve(rating)\n",
    "        if prediction != target and self.index_updater is not None:\n",
    "            mapping = {c.command.code: (c.command, c.index) for c in self.indexed_commands}\n",
    "            mapping[target] = (\n",
    "                mapping[target][0],\n",
    "                self.index_updater.update_index(mapping[target][1], indexed_query)\n",
    "            )\n",
    "            self.indexed_commands = [IndexedCommand(\n",
    "                command=c,\n",
    "                index=i\n",
    "            ) for c, i in mapping.values()]\n",
    "        \n",
    "    \n",
    "    def predict(self, query: str):\n",
    "        clean_query = self.preprocessor.preprocess(query)\n",
    "        indexed_query = self.indexer.get_index(clean_query)\n",
    "        rating = self.predictor.rate_commands(self.indexed_commands, indexed_query)\n",
    "        return self.resolver.resolve(rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"test_data/snips/train.csv\")\n",
    "test = pd.read_csv(\"test_data/snips/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PlayMusic               2014\n",
       " GetWeather              1996\n",
       " BookRestaurant          1981\n",
       " RateBook                1976\n",
       " SearchScreeningEvent    1952\n",
       " SearchCreativeWork      1947\n",
       " AddToPlaylist           1918\n",
       " Name: intent, dtype: int64,\n",
       " AddToPlaylist           124\n",
       " SearchScreeningEvent    107\n",
       " SearchCreativeWork      107\n",
       " GetWeather              104\n",
       " BookRestaurant           92\n",
       " PlayMusic                86\n",
       " RateBook                 80\n",
       " Name: intent, dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['intent'].value_counts(), test['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipeline(pipeline: Pipeline, df):\n",
    "    stats = {}\n",
    "    \n",
    "    start = timer()\n",
    "    \n",
    "    prediction = df['text'].map(pipeline.predict)\n",
    "    \n",
    "    stats['prediction_time'] = timer() - start\n",
    "    \n",
    "    stats['f1_score_micro'] = round(f1_score(test['intent'], prediction, average='micro'), 3)\n",
    "    stats['f1_score_macro'] = round(f1_score(test['intent'], prediction, average='macro'), 3)\n",
    "    \n",
    "    stats['detailed'] = {}\n",
    "    \n",
    "    for intent in df['intent'].unique():\n",
    "        TP_FN = (df['intent'] == intent)\n",
    "        TP = (prediction[TP_FN] == intent)\n",
    "        TP_FP = prediction == intent\n",
    "        stats['detailed'][intent] = {\n",
    "            \"recall\": round(TP.astype(int).sum() / TP_FN.astype(int).sum(), 3),\n",
    "            \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n",
    "        }\n",
    "    return stats\n",
    "\n",
    "\n",
    "\n",
    "def spawn_named_combinations(*args: List[List[Dict]]):\n",
    "    result = args[0]\n",
    "    \n",
    "    for candidates in args[1:]:\n",
    "        new_result = []\n",
    "        for r in result:\n",
    "            for c in candidates:\n",
    "                name_r = r['name']\n",
    "                name_c = c[\"name\"]\n",
    "                new_name = name_r + \"/\" + name_c\n",
    "                new_result.append({\n",
    "                    **r,\n",
    "                    **c,\n",
    "                    \"name\": new_name\n",
    "                })\n",
    "        result = new_result\n",
    "    return result\n",
    "    \n",
    "\n",
    "def test_pipeline_configs(configs: List[Dict], df, train_df = None):\n",
    "    result = {}\n",
    "    \n",
    "    for config in configs:\n",
    "        name = config['name']\n",
    "        pipeline = Pipeline(**{k: v for k, v in config.items() if k != \"name\"})\n",
    "        \n",
    "        if train_df is not None:\n",
    "            print(f\"Trainin pipeline {name}\")\n",
    "            train_df.apply(lambda row: pipeline.train(row['text'], row['intent']), axis=1)\n",
    "            print(f\"Training finished\")\n",
    "        \n",
    "        result[name] = test_pipeline(pipeline, df)\n",
    "        print(f\"Pipeline {name} was trained and estimated.\")\n",
    "    \n",
    "    print(\"\\n ===== Results ==== \")\n",
    "    for name, score in sorted(map(lambda x: (x[0], x[1]['f1_score_micro']), result.items()), key = lambda x: x[1], reverse=True):\n",
    "        print(f\"{score:.3f} | {name}\")\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_commands_description = [\n",
    "        Command(\n",
    "            code=\"PlayMusic\",\n",
    "            title=\"Play Music\",\n",
    "            description=\"Allows to listen music.\",\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"AddToPlaylist\",\n",
    "            title=\"Add to playlist\",\n",
    "            description=\"Adds track to playlist.\"\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"RateBook\",\n",
    "            title=\"Rate Book\",\n",
    "            description=\"Rates book.\",\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"SearchScreeningEvent\",\n",
    "            title=\"Search Screening Event\",\n",
    "            description=\"Searches for screening events\",\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"BookRestaurant\",\n",
    "            title=\"Book Restaurant\",\n",
    "            description=\"Books restaurant\",\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"GetWeather\",\n",
    "            title=\"Get Weather\",\n",
    "            description=\"Weather information\",\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"SearchCreativeWork\",\n",
    "            title=\"Search Creative Work\",\n",
    "            description=\"Searches for creative works, such as films or books.\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "extended_commands_description = [\n",
    "        Command(\n",
    "            code=\"PlayMusic\",\n",
    "            title=\"Play Music\",\n",
    "            description=\"Starts selected song from media.\",\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"AddToPlaylist\",\n",
    "            title=\"Add to playlist\",\n",
    "            description=\"Adds soundtrack to your media playlist.\"\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"RateBook\",\n",
    "            title=\"Rate Book\",\n",
    "            description=\"Adds your review about selected book.\",\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"SearchScreeningEvent\",\n",
    "            title=\"Search Screening Event\",\n",
    "            description=\"Searches for screening events\",\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"BookRestaurant\",\n",
    "            title=\"Book Restaurant\",\n",
    "            description=\"Books a selected restaurant for specific date and time\",\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"GetWeather\",\n",
    "            title=\"Get Weather\",\n",
    "            description=\"Provides information about the weather conditions, temperature, humidity for specific date.\",\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"SearchCreativeWork\",\n",
    "            title=\"Search Creative Work\",\n",
    "            description=\"Searches for creative works, such as films or books.\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "commands_with_5_examples = [\n",
    "        Command(\n",
    "            code=\"PlayMusic\",\n",
    "            examples=list(train[train['intent'] == \"PlayMusic\"]['text'][:5].values)\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"AddToPlaylist\",\n",
    "            examples=list(train[train['intent'] == \"AddToPlaylist\"]['text'][:5].values)\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"RateBook\",\n",
    "            examples=list(train[train['intent'] == \"RateBook\"]['text'][:5].values)\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"SearchScreeningEvent\",\n",
    "            examples=list(train[train['intent'] == \"SearchScreeningEvent\"]['text'][:5].values)\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"BookRestaurant\",\n",
    "            examples=list(train[train['intent'] == \"BookRestaurant\"]['text'][:5].values)\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"GetWeather\",\n",
    "            examples=list(train[train['intent'] == \"GetWeather\"]['text'][:5].values)\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"SearchCreativeWork\",\n",
    "            examples=list(train[train['intent'] == \"SearchCreativeWork\"]['text'][:5].values)\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "commands_with_10_examples = [\n",
    "        Command(\n",
    "            code=\"PlayMusic\",\n",
    "            examples=list(train[train['intent'] == \"PlayMusic\"]['text'][:10].values)\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"AddToPlaylist\",\n",
    "            examples=list(train[train['intent'] == \"AddToPlaylist\"]['text'][:10].values)\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"RateBook\",\n",
    "            examples=list(train[train['intent'] == \"RateBook\"]['text'][:10].values)\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"SearchScreeningEvent\",\n",
    "            examples=list(train[train['intent'] == \"SearchScreeningEvent\"]['text'][:10].values)\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"BookRestaurant\",\n",
    "            examples=list(train[train['intent'] == \"BookRestaurant\"]['text'][:10].values)\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"GetWeather\",\n",
    "            examples=list(train[train['intent'] == \"GetWeather\"]['text'][:10].values)\n",
    "        ),\n",
    "        Command(\n",
    "            code=\"SearchCreativeWork\",\n",
    "            examples=list(train[train['intent'] == \"SearchCreativeWork\"]['text'][:10].values)\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_with_st_removing = Preprocessor(remove_stop_words=True)\n",
    "preprocessor_without_st_removing = Preprocessor(remove_stop_words=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vooron/.local/share/virtualenvs/alt-7eI4X7JY/lib/python3.8/site-packages/spacy/util.py:758: UserWarning: [W095] Model 'en_core_web_md' (3.0.0) was trained with spaCy v3.0 and may not be 100% compatible with the current version (3.1.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "w2v_indexer = Word2VecIndexer(spacy.load(\"en_core_web_md\"))\n",
    "bert_indexer = BertIndexer(BertClient())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_updater_01 = IndexUpdater(0.1)\n",
    "index_updater_03 = IndexUpdater(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = spawn_named_combinations(\n",
    "    [\n",
    "        {\"name\": \"BERT\", \"indexer\": bert_indexer},\n",
    "        {\"name\": \"Word2Vec\", \"indexer\": w2v_indexer}\n",
    "    ],\n",
    "    [\n",
    "        {\"name\": \"RemoveST\", \"preprocessor\": preprocessor_with_st_removing}, \n",
    "        {\"name\": \"SaveST\", \"preprocessor\": preprocessor_without_st_removing}\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"name\": \"5ExamplesCommands\",\n",
    "            \"commands\": commands_with_5_examples,\n",
    "            \"commands_indexer\": examples_commands_indexer\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"10ExamplesCommands\",\n",
    "            \"commands\": commands_with_10_examples,\n",
    "            \"commands_indexer\": examples_commands_indexer\n",
    "        }, \n",
    "        {\n",
    "            \"name\": \"5MeanExamplesCommands\",\n",
    "            \"commands\": commands_with_5_examples,\n",
    "            \"commands_indexer\": mean_examples_commands_indexer\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"name\": \"10MeanExamplesCommands\",\n",
    "            \"commands\": commands_with_10_examples,\n",
    "            \"commands_indexer\": mean_examples_commands_indexer\n",
    "        },\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"name\": \"NoneIndexUpdater\",\n",
    "            \"index_updater\": None\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"IndexUpdater0.1\",\n",
    "            \"index_updater\": index_updater_01\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"IndexUpdater0.3\",\n",
    "            \"index_updater\": index_updater_03\n",
    "        },\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"name\": \"CosineDist\",\n",
    "            \"predictor\": Predictor(),\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"name\": \"default\",\n",
    "            \"resolver\": Resolver()\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vooron/.local/share/virtualenvs/alt-7eI4X7JY/lib/python3.8/site-packages/bert_serving/client/__init__.py:294: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  warnings.warn('some of your sentences have more tokens than \"max_seq_len=%d\" set on the server, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainin pipeline BERT/RemoveST/5ExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n",
      "/home/vooron/.local/share/virtualenvs/alt-7eI4X7JY/lib/python3.8/site-packages/bert_serving/client/__init__.py:294: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  warnings.warn('some of your sentences have more tokens than \"max_seq_len=%d\" set on the server, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/RemoveST/5ExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/RemoveST/5ExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n",
      "/home/vooron/.local/share/virtualenvs/alt-7eI4X7JY/lib/python3.8/site-packages/bert_serving/client/__init__.py:294: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  warnings.warn('some of your sentences have more tokens than \"max_seq_len=%d\" set on the server, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/RemoveST/5ExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/RemoveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n",
      "/home/vooron/.local/share/virtualenvs/alt-7eI4X7JY/lib/python3.8/site-packages/bert_serving/client/__init__.py:294: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  warnings.warn('some of your sentences have more tokens than \"max_seq_len=%d\" set on the server, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/RemoveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/RemoveST/10ExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n",
      "/home/vooron/.local/share/virtualenvs/alt-7eI4X7JY/lib/python3.8/site-packages/bert_serving/client/__init__.py:294: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  warnings.warn('some of your sentences have more tokens than \"max_seq_len=%d\" set on the server, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/RemoveST/10ExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/RemoveST/10ExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n",
      "/home/vooron/.local/share/virtualenvs/alt-7eI4X7JY/lib/python3.8/site-packages/bert_serving/client/__init__.py:294: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  warnings.warn('some of your sentences have more tokens than \"max_seq_len=%d\" set on the server, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/RemoveST/10ExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/RemoveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/RemoveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/RemoveST/5MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/RemoveST/5MeanExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/RemoveST/5MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline BERT/RemoveST/5MeanExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/RemoveST/5MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/RemoveST/5MeanExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/RemoveST/10MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline BERT/RemoveST/10MeanExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/RemoveST/10MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline BERT/RemoveST/10MeanExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/RemoveST/10MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n",
      "/home/vooron/.local/share/virtualenvs/alt-7eI4X7JY/lib/python3.8/site-packages/bert_serving/client/__init__.py:294: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  warnings.warn('some of your sentences have more tokens than \"max_seq_len=%d\" set on the server, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/RemoveST/10MeanExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/SaveST/5ExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n",
      "/home/vooron/.local/share/virtualenvs/alt-7eI4X7JY/lib/python3.8/site-packages/bert_serving/client/__init__.py:294: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  warnings.warn('some of your sentences have more tokens than \"max_seq_len=%d\" set on the server, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/SaveST/5ExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/SaveST/5ExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n",
      "/home/vooron/.local/share/virtualenvs/alt-7eI4X7JY/lib/python3.8/site-packages/bert_serving/client/__init__.py:294: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  warnings.warn('some of your sentences have more tokens than \"max_seq_len=%d\" set on the server, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/SaveST/5ExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/SaveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n",
      "/home/vooron/.local/share/virtualenvs/alt-7eI4X7JY/lib/python3.8/site-packages/bert_serving/client/__init__.py:294: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  warnings.warn('some of your sentences have more tokens than \"max_seq_len=%d\" set on the server, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/SaveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/SaveST/10ExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n",
      "/home/vooron/.local/share/virtualenvs/alt-7eI4X7JY/lib/python3.8/site-packages/bert_serving/client/__init__.py:294: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  warnings.warn('some of your sentences have more tokens than \"max_seq_len=%d\" set on the server, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/SaveST/10ExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/SaveST/10ExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n",
      "/home/vooron/.local/share/virtualenvs/alt-7eI4X7JY/lib/python3.8/site-packages/bert_serving/client/__init__.py:294: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  warnings.warn('some of your sentences have more tokens than \"max_seq_len=%d\" set on the server, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/SaveST/10ExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/SaveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/SaveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/SaveST/5MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/SaveST/5MeanExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/SaveST/5MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline BERT/SaveST/5MeanExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/SaveST/5MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline BERT/SaveST/5MeanExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/SaveST/10MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline BERT/SaveST/10MeanExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/SaveST/10MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline BERT/SaveST/10MeanExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline BERT/SaveST/10MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline BERT/SaveST/10MeanExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/RemoveST/5ExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/RemoveST/5ExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/RemoveST/5ExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/RemoveST/5ExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/RemoveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/RemoveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/RemoveST/10ExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/RemoveST/10ExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/RemoveST/10ExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/RemoveST/10ExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/RemoveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/RemoveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/RemoveST/5MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/RemoveST/5MeanExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/RemoveST/5MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/RemoveST/5MeanExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/RemoveST/5MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/RemoveST/5MeanExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/RemoveST/10MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/RemoveST/10MeanExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/RemoveST/10MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/RemoveST/10MeanExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/RemoveST/10MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/RemoveST/10MeanExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/SaveST/5ExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/SaveST/5ExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/SaveST/5ExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/SaveST/5ExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/SaveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/SaveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/SaveST/10ExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/SaveST/10ExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/SaveST/10ExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/SaveST/10ExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/SaveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/SaveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/SaveST/5MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d3a5a207d669>:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"precision\": round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 3)\n",
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Word2Vec/SaveST/5MeanExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/SaveST/5MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "Training finished\n",
      "Pipeline Word2Vec/SaveST/5MeanExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/SaveST/5MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/SaveST/5MeanExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/SaveST/10MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/SaveST/10MeanExamplesCommands/NoneIndexUpdater/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/SaveST/10MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/SaveST/10MeanExamplesCommands/IndexUpdater0.1/CosineDist/default was trained and estimated.\n",
      "Trainin pipeline Word2Vec/SaveST/10MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-5059dbbbc2c8>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished\n",
      "Pipeline Word2Vec/SaveST/10MeanExamplesCommands/IndexUpdater0.3/CosineDist/default was trained and estimated.\n",
      "\n",
      " ===== Results ==== \n",
      "0.820 | Word2Vec/RemoveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.789 | Word2Vec/RemoveST/5MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.779 | Word2Vec/RemoveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.741 | Word2Vec/SaveST/10MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.740 | Word2Vec/RemoveST/5MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.734 | Word2Vec/RemoveST/10MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.726 | Word2Vec/SaveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.726 | Word2Vec/SaveST/5MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.724 | BERT/SaveST/10MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.721 | Word2Vec/RemoveST/10ExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.721 | Word2Vec/RemoveST/10MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.719 | BERT/SaveST/5MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.714 | BERT/RemoveST/10MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.700 | Word2Vec/SaveST/5MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.697 | Word2Vec/SaveST/10ExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.684 | Word2Vec/RemoveST/5ExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.683 | Word2Vec/RemoveST/10ExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.670 | BERT/RemoveST/5MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.669 | Word2Vec/SaveST/5ExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.634 | Word2Vec/SaveST/10MeanExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.629 | Word2Vec/SaveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.624 | Word2Vec/RemoveST/5ExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.617 | BERT/SaveST/5MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.607 | Word2Vec/RemoveST/10MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.606 | BERT/SaveST/10MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.590 | Word2Vec/SaveST/10ExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.580 | BERT/RemoveST/10MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.501 | Word2Vec/RemoveST/5MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.486 | Word2Vec/SaveST/5ExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.480 | Word2Vec/SaveST/10MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.464 | BERT/RemoveST/10MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.427 | Word2Vec/SaveST/5MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.389 | BERT/SaveST/5ExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.389 | BERT/SaveST/10ExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.370 | BERT/RemoveST/5MeanExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.361 | BERT/RemoveST/5MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.347 | BERT/SaveST/5MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.333 | BERT/RemoveST/10ExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.321 | BERT/SaveST/10MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.316 | BERT/RemoveST/5ExamplesCommands/NoneIndexUpdater/CosineDist/default\n",
      "0.153 | BERT/RemoveST/5ExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.153 | BERT/RemoveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.153 | BERT/RemoveST/10ExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.153 | BERT/RemoveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.137 | BERT/SaveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.137 | BERT/SaveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
      "0.136 | BERT/SaveST/5ExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
      "0.136 | BERT/SaveST/10ExamplesCommands/IndexUpdater0.1/CosineDist/default\n"
     ]
    }
   ],
   "source": [
    "details = test_pipeline_configs(configs, test, train_df=pd.concat([train[train.intent == intent].head(70) for intent in train.intent.unique()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snips f1_micro(Ð¿Ð¾ 70) = 0.79\n",
    "# snips f1_micro(Ð¿Ð¾ 286 - Ð²ÑÐµÐ³Ð¾ 2000) = 0.93\n",
    "\n",
    "\n",
    "# With index updating 2002 (uniform) training samples\n",
    "# 0.779 | Word2Vec/RemoveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
    "# 0.759 | Word2Vec/RemoveST/10ExamplesCommands/IndexUpdater0.1/CosineDist/default\n",
    "\n",
    "\n",
    "# With index updating 70 (uniform) training samples\n",
    "# 0.770 | Word2Vec/RemoveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
    "# 0.759 | Word2Vec/RemoveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
    "\n",
    "\n",
    "# With index updating 150 (random) training samples\n",
    "# 0.819 | Word2Vec/SaveST/10ExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
    "# 0.804 | Word2Vec/SaveST/10MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
    "# 0.791 | Word2Vec/SaveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
    "# 0.754 | Word2Vec/SaveST/5MeanExamplesCommands/IndexUpdater0.3/CosineDist/default\n",
    "\n",
    "\n",
    "# 0.683 | Word2Vec/RemoveST/10ExamplesCommands/CosineDist/default\n",
    "# 0.64  | Word2Vec/RemoveST/ExtendedCommands/CosineDist/default\n",
    "# 0.624 | Word2Vec/RemoveST/5ExamplesCommands/CosineDist/default\n",
    "# 0.617 | BERT/SaveST/5MeanExamplesCommands/CosineDist/default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction_time': 2.990687382000033,\n",
       " 'f1_score_micro': 0.77,\n",
       " 'f1_score_macro': 0.784,\n",
       " 'detailed': {'AddToPlaylist': {'recall': 0.798, 'precision': 0.971},\n",
       "  'BookRestaurant': {'recall': 0.674, 'precision': 0.969},\n",
       "  'GetWeather': {'recall': 0.952, 'precision': 0.884},\n",
       "  'PlayMusic': {'recall': 0.767, 'precision': 0.857},\n",
       "  'SearchScreeningEvent': {'recall': 0.785, 'precision': 0.609},\n",
       "  'SearchCreativeWork': {'recall': 0.598, 'precision': 0.457},\n",
       "  'RateBook': {'recall': 0.812, 'precision': 0.97}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details['Word2Vec/RemoveST/5ExamplesCommands/IndexUpdater0.3/CosineDist/default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction_time': 65.00556309500098,\n",
       " 'f1_score_micro': 0.701,\n",
       " 'f1_score_macro': 0.684,\n",
       " 'detailed': {'AddToPlaylist': {'recall': 0.831, 'precision': 0.786},\n",
       "  'BookRestaurant': {'recall': 0.891, 'precision': 0.573},\n",
       "  'GetWeather': {'recall': 0.644, 'precision': 0.957},\n",
       "  'PlayMusic': {'recall': 0.221, 'precision': 0.95},\n",
       "  'SearchScreeningEvent': {'recall': 0.748, 'precision': 0.784},\n",
       "  'SearchCreativeWork': {'recall': 0.794, 'precision': 0.489},\n",
       "  'RateBook': {'recall': 0.688, 'precision': 0.917}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details['BERT/RemoveST/10MeanExamplesCommands/IndexUpdater0.1/CosineDist/default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_commands(indexed_commands_mapping, valid_intent, imballance_coefficient):\n",
    "    commands = [indexed_commands_mapping[valid_intent]]\n",
    "    \n",
    "    other_commands_keys = set(indexed_commands_mapping.keys()) - {valid_intent}\n",
    "    \n",
    "    for key in random.sample(other_commands_keys, imballance_coefficient):\n",
    "        commands.append(indexed_commands_mapping[key])\n",
    "    \n",
    "    return commands\n",
    "        \n",
    "    \n",
    "\n",
    "def main(from_df, commands, indexer, preprocessor, commands_indexer, imballance_coefficient = 1):\n",
    "    \n",
    "    indexed_commands = commands_indexer(commands, preprocessor, indexer)\n",
    "    indexed_commands_mapping = {c.command.code: c for c in indexed_commands}\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # fill dataset\n",
    "    for _, row in from_df.iterrows():\n",
    "        \n",
    "        text_index = w2v_indexer.get_index(preprocessor.preprocess(row[\"text\"]))  # add preprocessing\n",
    "        for ic in _get_commands(indexed_commands_mapping, row[\"intent\"], imballance_coefficient):\n",
    "            X.append([*text_index, *ic.index, (np.dot(text_index, ic.index)/(np.linalg.norm(text_index)*np.linalg.norm(ic.index)) + 1) / 2])\n",
    "            y.append(int(row[\"intent\"] == ic.command.code))\n",
    "    \n",
    "    X, y = pd.DataFrame(X), pd.DataFrame(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-b841ec81f613>:26: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  X.append([*text_index, *ic.index, (np.dot(text_index, ic.index)/(np.linalg.norm(text_index)*np.linalg.norm(ic.index)) + 1) / 2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.1 s, sys: 270 ms, total: 34.3 s\n",
      "Wall time: 34.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = main(pd.concat([train[train.intent == intent].head(1000) for intent in train.intent.unique()]), commands_with_5_examples, w2v_indexer, preprocessor_with_st_removing, mean_examples_commands_indexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = X.isna().astype(int).sum(axis=1) == 0\n",
    "X = X[mask]\n",
    "y = y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best CV score: 0.7714667209697723\n",
      "f1 0.785\n",
      "precision 0.731\n",
      "recall 0.848\n",
      "CPU times: user 15.3 s, sys: 11.9 s, total: 27.3 s\n",
      "Wall time: 47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "config = {\n",
    "    \"est__loss\": ['log',],\n",
    "    \"est__alpha\": [1e-3, 1e-2,],\n",
    "    \"pca__n_components\": [200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"pca\", PCA()),\n",
    "    (\"est\", SGDClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "gs_cv = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=config,\n",
    "    scoring=\"f1\",\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "gs_cv.fit(X_train, y_train.values.reshape(-1))\n",
    "\n",
    "print(f\"Best CV score: {gs_cv.best_score_}\")\n",
    "\n",
    "prediction = gs_cv.predict(X_test)\n",
    "\n",
    "print(f\"f1 {round(f1_score(y_test, prediction), 3)}\")\n",
    "\n",
    "print(f\"precision {round(precision_score(y_test, prediction), 3)}\")\n",
    "print(f\"recall {round(recall_score(y_test, prediction), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'est__alpha': 0.001, 'est__loss': 'log', 'pca__n_components': 300}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cv.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2 vectors - 35000 uniform examples - ~45%\n",
    "PCA(2 vectors)\n",
    "2 vectors + CosDist ~ 75%\n",
    "PCA(2 vectors + CosDist)(300) ~ 79% (a little bit better then just CosDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
