{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from bert_serving.client import BertClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple, Optional, Dict, List, Tuple\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "class Command(NamedTuple):\n",
    "    code: str\n",
    "    title: str\n",
    "    description: str\n",
    "\n",
    "\n",
    "class IndexedCommand(NamedTuple):\n",
    "    command: Command\n",
    "    index: np.ndarray\n",
    "\n",
    "        \n",
    "#     parameters: Optional[List['Parameter']] = None\n",
    "\n",
    "# class Parameter(metaclass=ABCMeta):\n",
    "#     key: str\n",
    "    \n",
    "#     def __init__(self, key: str):\n",
    "#         if not key:\n",
    "#             raise Exception(\"Parameter key is mandatory\")\n",
    "#         self.key = key\n",
    "    \n",
    "#     @abstractmethod\n",
    "#     def is_appropriate(self, token: str) -> bool:\n",
    "#         pass\n",
    "    \n",
    "#     @abstractmethod\n",
    "#     def transform(self, tokem: str) -> any:\n",
    "#         pass\n",
    "\n",
    "    \n",
    "# class IntegerParameter(Parameter):\n",
    "    \n",
    "#     def is_appropriate(self, token: str) -> bool:\n",
    "#         return token.isnumeric()\n",
    "    \n",
    "#     def transform(self, token: str) -> int:\n",
    "#         return int(token)\n",
    "\n",
    "# class ExactStringMatchParameter(Parameter):\n",
    "    \n",
    "#     vocab: Dict[str, str]  # key - String that appears in the text, value - key\n",
    "        \n",
    "#     def __init__(self, key: str, vocab: Dict[str, str]):\n",
    "#         super(ExactStringMatchParameter, self).__init__(key)\n",
    "#         if not vocab:\n",
    "#             raise Exception(\"Parameter vocab is mandatory\")\n",
    "#         self.vocab = {k.lower(): v for k, v in vocab.items()}\n",
    "    \n",
    "#     def is_appropriate(self, token: str) -> bool:\n",
    "#         return token.lower() in self.vocab\n",
    "    \n",
    "#     def transform(self, token: str) -> int:\n",
    "#         return self.vocab.get(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Preprocessor:\n",
    "    \n",
    "    def preprocess(self, text: str) -> str:\n",
    "        lc_cleared = text.lower()\n",
    "        lc_cleared = re.sub(r\"[0-9.,?/()\\[\\]\\'\\\":#â„–$\\t;<>!+\\-_=%{}><~`|]\", \" \", lc_cleared)\n",
    "        lc_cleared = re.sub(r\"\\s+\", \" \", lc_cleared)\n",
    "        return lc_cleared.strip()\n",
    "\n",
    "\n",
    "class Indexer(metaclass=ABCMeta):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_index(self, text: str) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    \n",
    "class BertIndexer(Indexer):\n",
    "    \n",
    "    def __init__(self, mapper):\n",
    "        self.mapper = mapper\n",
    "    \n",
    "    def get_index(self, text: str) -> np.ndarray:\n",
    "        return self.mapper.encode([text])[0]\n",
    "\n",
    "\n",
    "class Predictor:\n",
    "    \n",
    "    def rate_commands(self, indexed_commands: List[IndexedCommand], query_index: np.ndarray) -> List[Tuple[str, float]]:\n",
    "        target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n",
    "        \n",
    "        commands, commands_indexes = target_vocab[::, 0], target_vocab[::, 1]\n",
    "        \n",
    "        a = np.array([np.array(x) for x in commands_indexes])\n",
    "        b = query_index\n",
    "\n",
    "        predict = (np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b)) + 1) / 2\n",
    "\n",
    "        return list(sorted(zip(commands, predict), key=lambda x: x[1], reverse=True))\n",
    "        \n",
    "\n",
    "class Resolver:\n",
    "    \n",
    "    def resolve(self, prediction: List[Tuple[str, float]]) -> str:\n",
    "        return prediction[0][0]\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    preprocessor: Preprocessor\n",
    "    indexer: Indexer\n",
    "    predictor: Predictor\n",
    "    resolver: Resolver\n",
    "    indexed_commands: List[IndexedCommand]\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        preprocessor: Preprocessor,\n",
    "        indexer: Indexer,\n",
    "        predictor: Predictor,\n",
    "        resolver: Resolver,\n",
    "        indexed_commands: List[IndexedCommand]\n",
    "    ):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.indexer = indexer\n",
    "        self.predictor = predictor\n",
    "        self.resolver = resolver\n",
    "        self.indexed_commands = indexed_commands\n",
    "    \n",
    "    def predict(self, query: str):\n",
    "        clean_query = self.preprocessor.preprocess(query)\n",
    "        indexed_query = self.indexer.get_index(clean_query)\n",
    "        rating = self.predictor.rate_commands(self.indexed_commands, indexed_query)\n",
    "        return self.resolver.resolve(rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "commands = [\n",
    "    Command(\n",
    "        code=\"PlayMusic\",\n",
    "        title=\"Play Music\",\n",
    "        description=\"Allows to listen music.\",\n",
    "    ),\n",
    "    Command(\n",
    "        code=\"AddToPlaylist\",\n",
    "        title=\"Add to playlist\",\n",
    "        description=\"Adds track to playlist.\"\n",
    "    ),\n",
    "    Command(\n",
    "        code=\"RateBook\",\n",
    "        title=\"Rate Book\",\n",
    "        description=\"Rates book.\",\n",
    "    ),\n",
    "    Command(\n",
    "        code=\"SearchScreeningEvent\",\n",
    "        title=\"Search Screening Event\",\n",
    "        description=\"Searches for screening events\",\n",
    "    ),\n",
    "    Command(\n",
    "        code=\"BookRestaurant\",\n",
    "        title=\"Book Restaurant\",\n",
    "        description=\"Books restaurant\",\n",
    "    ),\n",
    "    Command(\n",
    "        code=\"GetWeather\",\n",
    "        title=\"Get Weather\",\n",
    "        description=\"Weather information\",\n",
    "    ),\n",
    "    Command(\n",
    "        code=\"SearchCreativeWork\",\n",
    "        title=\"Search Creative Work\",\n",
    "        description=\"Searches for creative works, such as films or books.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "# Parameters parsing (Raw)\n",
    "# Preprocess\n",
    "# Indexing\n",
    "# Predicting\n",
    "# Resolving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bc = BertClient()\n",
    "\n",
    "preprocessor = Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_commands = []\n",
    "\n",
    "for command in commands:\n",
    "    text_to_index = preprocessor.preprocess(command.title + \" \" + command.description)\n",
    "    indexed_commands.append(IndexedCommand(\n",
    "        command=command,\n",
    "        index=bc.encode([text_to_index])[0]\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"test_data/snips/train.csv\")\n",
    "test = pd.read_csv(\"test_data/snips/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PlayMusic', 'AddToPlaylist', 'RateBook', 'SearchScreeningEvent',\n",
       "       'BookRestaurant', 'GetWeather', 'SearchCreativeWork'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['intent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PlayMusic               2014\n",
       "GetWeather              1996\n",
       "BookRestaurant          1981\n",
       "RateBook                1976\n",
       "SearchScreeningEvent    1952\n",
       "SearchCreativeWork      1947\n",
       "AddToPlaylist           1918\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AddToPlaylist           124\n",
       "SearchScreeningEvent    107\n",
       "SearchCreativeWork      107\n",
       "GetWeather              104\n",
       "BookRestaurant           92\n",
       "PlayMusic                86\n",
       "RateBook                 80\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(preprocessor, BertIndexer(bc), Predictor(), Resolver(), indexed_commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-9aa710245b60>:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  target_vocab = np.array(list(map(lambda c: np.array((c.command.code, c.index)), indexed_commands)))\n"
     ]
    }
   ],
   "source": [
    "prediction = test['text'].map(pipeline.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Bert with cosine distance ===\n",
      "f1_score_micro 0.48 \n",
      "\n",
      "--- Detailed ---\n",
      "\n",
      "PlayMusic\n",
      "  Recall: 0.47\n",
      "  Precision: 0.33\n",
      "\n",
      "AddToPlaylist\n",
      "  Recall: 0.96\n",
      "  Precision: 0.61\n",
      "\n",
      "RateBook\n",
      "  Recall: 0.74\n",
      "  Precision: 0.4\n",
      "\n",
      "SearchScreeningEvent\n",
      "  Recall: 0.21\n",
      "  Precision: 0.37\n",
      "\n",
      "BookRestaurant\n",
      "  Recall: 0.95\n",
      "  Precision: 0.54\n",
      "\n",
      "GetWeather\n",
      "  Recall: 0.06\n",
      "  Precision: 1.0\n",
      "\n",
      "SearchCreativeWork\n",
      "  Recall: 0.02\n",
      "  Precision: 0.67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Bert with cosine distance ===\")\n",
    "print(\"f1_score_micro\", round(f1_score(test['intent'], prediction, average='micro'), 2), '\\n')\n",
    "\n",
    "print(\"--- Detailed ---\\n\")\n",
    "for intent in train['intent'].unique():\n",
    "    print(f\"{intent}\")\n",
    "    \n",
    "    TP_FN = (test['intent'] == intent)\n",
    "    TP = (prediction[TP_FN] == intent)\n",
    "    \n",
    "    print(\"  Recall:\", round(TP.astype(int).sum() / TP_FN.astype(int).sum(), 2))\n",
    "    \n",
    "    TP_FP = prediction == intent\n",
    "    print(\"  Precision:\", round(TP.astype(int).sum() / TP_FP.astype(int).sum(), 2))\n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
